{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Normal', 'Stroke']\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize images\n",
    "])\n",
    "\n",
    "# Load dataset using ImageFolder (auto-labels folders as class labels)\n",
    "def load_dataset(data_path, batch_size=16, shuffle=True):\n",
    "    dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return dataloader, dataset.classes  # Also return class names\n",
    "\n",
    "# Load Train, Test, Validation datasets\n",
    "train_loader, class_names = load_dataset(\"Train\", batch_size=16)\n",
    "test_loader, _ = load_dataset(\"Test\", batch_size=16, shuffle=False)\n",
    "val_loader, _ = load_dataset(\"Validation\", batch_size=16, shuffle=False)\n",
    "\n",
    "# Print class names (should be ['normal', 'stroke'])\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def create_srgan_generator():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1),\n",
    "        nn.Tanh()\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_srgan(epochs=50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = create_srgan_generator().to(device)  \n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Training Epoch {epoch+1}/{epochs}...\")\n",
    "    \n",
    "    torch.save(model.state_dict(), \"srgan_model.pth\")\n",
    "    print(\"✅ SRGAN Model Saved!\")\n",
    "\n",
    "train_srgan()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss 0.021207906305789948\n",
      "Epoch 2: Loss 0.013007164932787418\n",
      "Epoch 3: Loss 0.006572111509740353\n",
      "Epoch 4: Loss 0.004941129591315985\n",
      "Epoch 5: Loss 0.004091570619493723\n",
      "Epoch 6: Loss 0.0032092754263430834\n",
      "Epoch 7: Loss 0.0027026108000427485\n",
      "Epoch 8: Loss 0.0022438964806497097\n",
      "Epoch 9: Loss 0.0025238629896193743\n",
      "Epoch 10: Loss 0.0019385587656870484\n",
      "Epoch 11: Loss 0.001775426440872252\n",
      "Epoch 12: Loss 0.0018056790577247739\n",
      "Epoch 13: Loss 0.0015430934727191925\n",
      "Epoch 14: Loss 0.0018672632286325097\n",
      "Epoch 15: Loss 0.001385255018249154\n",
      "Epoch 16: Loss 0.0015486415941268206\n",
      "Epoch 17: Loss 0.0017663551261648536\n",
      "Epoch 18: Loss 0.0016322728479281068\n",
      "Epoch 19: Loss 0.00148071872536093\n",
      "Epoch 20: Loss 0.0013375234557315707\n",
      "Epoch 21: Loss 0.0013909657718613744\n",
      "Epoch 22: Loss 0.0009587527019903064\n",
      "Epoch 23: Loss 0.00128195493016392\n",
      "Epoch 24: Loss 0.001232074573636055\n",
      "Epoch 25: Loss 0.001221893006004393\n",
      "Epoch 26: Loss 0.0012226564576849341\n",
      "Epoch 27: Loss 0.0013223313726484776\n",
      "Epoch 28: Loss 0.0011034865165129304\n",
      "Epoch 29: Loss 0.0008632234530523419\n",
      "Epoch 30: Loss 0.0010809912346303463\n",
      "Epoch 31: Loss 0.0011095753870904446\n",
      "Epoch 32: Loss 0.0010906015522778034\n",
      "Epoch 33: Loss 0.0008752925787121058\n",
      "Epoch 34: Loss 0.0012619908666238189\n",
      "Epoch 35: Loss 0.001029730075970292\n",
      "Epoch 36: Loss 0.0010764894541352987\n",
      "Epoch 37: Loss 0.0009129478130489588\n",
      "Epoch 38: Loss 0.0009428280172869563\n",
      "Epoch 39: Loss 0.0010406464571133256\n",
      "Epoch 40: Loss 0.0008602171437814832\n",
      "Epoch 41: Loss 0.0008957309764809906\n",
      "Epoch 42: Loss 0.0008743366342969239\n",
      "Epoch 43: Loss 0.0011055568465963006\n",
      "Epoch 44: Loss 0.0010165405692532659\n",
      "Epoch 45: Loss 0.0007266193861141801\n",
      "Epoch 46: Loss 0.0007884484948590398\n",
      "Epoch 47: Loss 0.001078322995454073\n",
      "Epoch 48: Loss 0.0009239529026672244\n",
      "Epoch 49: Loss 0.0009076222777366638\n",
      "Epoch 50: Loss 0.0007570861489512026\n",
      "✅ Denoising Model Saved!\n"
     ]
    }
   ],
   "source": [
    "def create_denoising_generator():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
    "    )\n",
    "\n",
    "def train_denoising_gan(epochs=50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = create_denoising_generator().to(device)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for imgs, _ in train_loader:\n",
    "            noisy_imgs = imgs + 0.1 * torch.randn_like(imgs)  # Add noise\n",
    "            noisy_imgs, imgs = noisy_imgs.to(device), imgs.to(device)\n",
    "\n",
    "            output = model(noisy_imgs)\n",
    "            loss = criterion(output, imgs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss {loss.item()}\")\n",
    "\n",
    "    torch.save(model, \"denoising_model.pth\")\n",
    "    print(\"✅ Denoising Model Saved!\")\n",
    "\n",
    "train_denoising_gan()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss 0.017321070656180382\n",
      "Epoch 2: Loss 0.009665808640420437\n",
      "Epoch 3: Loss 0.005323986988514662\n",
      "Epoch 4: Loss 0.0038219131529331207\n",
      "Epoch 5: Loss 0.0025817251298576593\n",
      "Epoch 6: Loss 0.0020207948982715607\n",
      "Epoch 7: Loss 0.00126533186994493\n",
      "Epoch 8: Loss 0.0010422603227198124\n",
      "Epoch 9: Loss 0.0007417536107823253\n",
      "Epoch 10: Loss 0.0006573192658834159\n",
      "Epoch 11: Loss 0.0006549193640239537\n",
      "Epoch 12: Loss 0.00038285410846583545\n",
      "Epoch 13: Loss 0.00025636624195612967\n",
      "Epoch 14: Loss 0.00029580690898001194\n",
      "Epoch 15: Loss 0.0002305494708707556\n",
      "Epoch 16: Loss 0.0003672844322863966\n",
      "Epoch 17: Loss 0.00017250275413971394\n",
      "Epoch 18: Loss 0.00022744493617210537\n",
      "Epoch 19: Loss 0.00029675077530555427\n",
      "Epoch 20: Loss 0.00023643599706701934\n",
      "Epoch 21: Loss 0.00024407453020103276\n",
      "Epoch 22: Loss 0.0001901862706290558\n",
      "Epoch 23: Loss 0.0002247558004455641\n",
      "Epoch 24: Loss 0.00017694482812657952\n",
      "Epoch 25: Loss 0.00018207848188467324\n",
      "Epoch 26: Loss 0.00012264672841411084\n",
      "Epoch 27: Loss 0.00010450708941789344\n",
      "Epoch 28: Loss 0.00011897515651071444\n",
      "Epoch 29: Loss 7.87954413681291e-05\n",
      "Epoch 30: Loss 0.0001055628526955843\n",
      "Epoch 31: Loss 0.00016802122991066426\n",
      "Epoch 32: Loss 8.175070979632437e-05\n",
      "Epoch 33: Loss 9.066978236660361e-05\n",
      "Epoch 34: Loss 8.183638419723138e-05\n",
      "Epoch 35: Loss 8.426736167166382e-05\n",
      "Epoch 36: Loss 6.086338544264436e-05\n",
      "Epoch 37: Loss 8.71227020979859e-05\n",
      "Epoch 38: Loss 7.738442945992574e-05\n",
      "Epoch 39: Loss 5.935399531153962e-05\n",
      "Epoch 40: Loss 5.0238097173860297e-05\n",
      "Epoch 41: Loss 6.894853140693158e-05\n",
      "Epoch 42: Loss 3.854179158224724e-05\n",
      "Epoch 43: Loss 5.872426845598966e-05\n",
      "Epoch 44: Loss 4.24682475568261e-05\n",
      "Epoch 45: Loss 2.8756459869327955e-05\n",
      "Epoch 46: Loss 6.179534830152988e-05\n",
      "Epoch 47: Loss 5.976811007712968e-05\n",
      "Epoch 48: Loss 5.969221456325613e-05\n",
      "Epoch 49: Loss 3.9489783375756815e-05\n",
      "Epoch 50: Loss 4.123367398278788e-05\n",
      "✅ CycleGAN Model Saved!\n"
     ]
    }
   ],
   "source": [
    "def create_cyclegan_generator():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
    "    )\n",
    "\n",
    "def train_cyclegan(epochs=50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = create_cyclegan_generator().to(device)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for imgs, _ in train_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, imgs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss {loss.item()}\")\n",
    "\n",
    "    torch.save(model, \"cyclegan_model.pth\")\n",
    "    print(\"✅ CycleGAN Model Saved!\")\n",
    "\n",
    "train_cyclegan()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/predict/srgan/\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = create_srgan_generator().to(device)\n",
    "    \n",
    "    # Load the model with map_location to handle CPU-only machines\n",
    "    model.load_state_dict(torch.load(\"srgan_model.pth\", map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # Read and preprocess the input image\n",
    "    image = Image.open(file.file).convert('RGB')\n",
    "    transform = transforms.ToTensor()\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "\n",
    "    # Convert output tensor to image\n",
    "    output_image = transforms.ToPILImage()(output.squeeze(0).cpu())\n",
    "\n",
    "    # Save or return the output image\n",
    "    output_image.save(\"output_image.png\")\n",
    "    \n",
    "    return {\"message\": \"Super-resolution image generated and saved as output_image.png\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
